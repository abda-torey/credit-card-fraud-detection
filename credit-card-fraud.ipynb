{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREDIT CARD FRAUD DETECTION PROJECT\n",
    "\n",
    "\n",
    "**we will be using a dataset from kaggle to identify if a certain type of bank transaction is a fraud or not, this project is an example of  classification dataset, we will  examine different  models to come up with one that best detects fraud.The description below is an excerpt from kaggle**\n",
    "     \n",
    "         \"The dataset contains transactions made by credit cards in september 2013 by European card holders. this dataset   presents transactions that occured within two days\"\n",
    " \n",
    " the data is highly unbalanced, we will use Resampling techniques to overcome that challenge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regular EDA and Plotting libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# importing our models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# model evaluators\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV,cross_val_score,GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix,f1_score,recall_score,precision_score,plot_roc_curve,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.229658</td>\n",
       "      <td>0.141004</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>1.202613</td>\n",
       "      <td>0.191881</td>\n",
       "      <td>0.272708</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.081213</td>\n",
       "      <td>0.464960</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167716</td>\n",
       "      <td>-0.270710</td>\n",
       "      <td>-0.154104</td>\n",
       "      <td>-0.780055</td>\n",
       "      <td>0.750137</td>\n",
       "      <td>-0.257237</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.644269</td>\n",
       "      <td>1.417964</td>\n",
       "      <td>1.074380</td>\n",
       "      <td>-0.492199</td>\n",
       "      <td>0.948934</td>\n",
       "      <td>0.428118</td>\n",
       "      <td>1.120631</td>\n",
       "      <td>-3.807864</td>\n",
       "      <td>0.615375</td>\n",
       "      <td>...</td>\n",
       "      <td>1.943465</td>\n",
       "      <td>-1.015455</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>-0.649709</td>\n",
       "      <td>-0.415267</td>\n",
       "      <td>-0.051634</td>\n",
       "      <td>-1.206921</td>\n",
       "      <td>-1.085339</td>\n",
       "      <td>40.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.894286</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>-0.113192</td>\n",
       "      <td>-0.271526</td>\n",
       "      <td>2.669599</td>\n",
       "      <td>3.721818</td>\n",
       "      <td>0.370145</td>\n",
       "      <td>0.851084</td>\n",
       "      <td>-0.392048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.268092</td>\n",
       "      <td>-0.204233</td>\n",
       "      <td>1.011592</td>\n",
       "      <td>0.373205</td>\n",
       "      <td>-0.384157</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.142404</td>\n",
       "      <td>93.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.338262</td>\n",
       "      <td>1.119593</td>\n",
       "      <td>1.044367</td>\n",
       "      <td>-0.222187</td>\n",
       "      <td>0.499361</td>\n",
       "      <td>-0.246761</td>\n",
       "      <td>0.651583</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>-0.736727</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.246914</td>\n",
       "      <td>-0.633753</td>\n",
       "      <td>-0.120794</td>\n",
       "      <td>-0.385050</td>\n",
       "      <td>-0.069733</td>\n",
       "      <td>0.094199</td>\n",
       "      <td>0.246219</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "5   2.0 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n",
       "6   4.0  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708 -0.005159   \n",
       "7   7.0 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118  1.120631   \n",
       "8   7.0 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818  0.370145   \n",
       "9   9.0 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "5  0.260314 -0.568671  ... -0.208254 -0.559825 -0.026398 -0.371427 -0.232794   \n",
       "6  0.081213  0.464960  ... -0.167716 -0.270710 -0.154104 -0.780055  0.750137   \n",
       "7 -3.807864  0.615375  ...  1.943465 -1.015455  0.057504 -0.649709 -0.415267   \n",
       "8  0.851084 -0.392048  ... -0.073425 -0.268092 -0.204233  1.011592  0.373205   \n",
       "9  0.069539 -0.736727  ... -0.246914 -0.633753 -0.120794 -0.385050 -0.069733   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "5  0.105915  0.253844  0.081080    3.67      0  \n",
       "6 -0.257237  0.034507  0.005168    4.99      0  \n",
       "7 -0.051634 -1.206921 -1.085339   40.80      0  \n",
       "8 -0.384157  0.011747  0.142404   93.20      0  \n",
       "9  0.094199  0.246219  0.083076    3.68      0  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## importing data\n",
    "df = pd.read_csv(\"./data/creditcard.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "# check for null values\n",
    "df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>1.165980e-15</td>\n",
       "      <td>3.416908e-16</td>\n",
       "      <td>-1.373150e-15</td>\n",
       "      <td>2.086869e-15</td>\n",
       "      <td>9.604066e-16</td>\n",
       "      <td>1.490107e-15</td>\n",
       "      <td>-5.556467e-16</td>\n",
       "      <td>1.177556e-16</td>\n",
       "      <td>-2.406455e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.656562e-16</td>\n",
       "      <td>-3.444850e-16</td>\n",
       "      <td>2.578648e-16</td>\n",
       "      <td>4.471968e-15</td>\n",
       "      <td>5.340915e-16</td>\n",
       "      <td>1.687098e-15</td>\n",
       "      <td>-3.666453e-16</td>\n",
       "      <td>-1.220404e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  1.165980e-15  3.416908e-16 -1.373150e-15  2.086869e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   9.604066e-16  1.490107e-15 -5.556467e-16  1.177556e-16 -2.406455e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.656562e-16 -3.444850e-16  2.578648e-16  4.471968e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   5.340915e-16  1.687098e-15 -3.666453e-16 -1.220404e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of transactions that are fraud 0.1727485630620034 %\n",
      "percentage of transactions that are not fraud is 99.83 %\n"
     ]
    }
   ],
   "source": [
    "fraud = df[df.Class==1]\n",
    "not_fraud = df[df.Class==0]\n",
    "not_fraud_percentage = len(not_fraud)/len(df) *100\n",
    "fraud_percentage = len(fraud)/len(df) *100\n",
    "print(\"percentage of transactions that are fraud\",fraud_percentage,\"%\")\n",
    "print(\"percentage of transactions that are not fraud is\",round(not_fraud_percentage,2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((284315, 31), (492, 31))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_fraud.shape,fraud.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " from the code above, you can see that our observation at the start has been proven right, the dataset is greatly unbalanced, we will use resampling module from sciKit-learn      to oversample the minority class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### oversampling minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((284807, 30), (284807,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's split the data\n",
    "X = df.drop('Class',axis=1)\n",
    "y = df.Class\n",
    "\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state=21)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we do not oversample before splitting the data, as this can allow the exact same observations to be present in both the test and train sets.\n",
    "this can allow our model to simply memorize specific data points and cause overfitting and poor generalization  to the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in the code that follows, we will upsample the test data on it is own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56962, 31)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concat test data back together\n",
    "test_concat = pd.concat([X_test,y_test],axis=1)\n",
    "test_concat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109, 56853)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_test_fraud = test_concat[test_concat.Class==1]\n",
    "not_test_fraud = test_concat[test_concat.Class==0]\n",
    "len(is_test_fraud),len(not_test_fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    56853\n",
       "0    56853\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "is_test_fraud_upsampled = resample(is_test_fraud,replace=True,n_samples=len(not_test_fraud),random_state=21)\n",
    "\n",
    "final_test_concat = pd.concat([is_test_fraud_upsampled,not_test_fraud])\n",
    "final_test_concat.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1137, 30), (1137,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_final_test_concat = final_test_concat.sample(frac=0.01,random_state=21)\n",
    "x_test = last_final_test_concat.drop('Class',axis=1)\n",
    "y_test = last_final_test_concat.Class\n",
    "\n",
    "x_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's get into our train data and start upsampling the minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(227845, 31)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat our training data back together\n",
    "x = pd.concat([X_train,y_train],axis=1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(383, 227462)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_fraud = x[x.Class==1]\n",
    "fraud_not = x[x.Class==0]\n",
    "len(is_fraud),len(fraud_not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(227462, 31)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## oversampling the minority class which is 'is_fraud'\n",
    "is_fraud_upsampled = resample(is_fraud,replace=True,n_samples=len(fraud_not),random_state=21)\n",
    "is_fraud_upsampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    227462\n",
       "0    227462\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's concat our data back together\n",
    "upsampled_data = pd.concat([fraud_not,is_fraud_upsampled])\n",
    "upsampled_data.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(668, 697, 1365)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "final_upsampled = upsampled_data.sample(frac=0.003,random_state=21)\n",
    "y_train = final_upsampled.Class\n",
    "x_train = final_upsampled.drop('Class',axis = 1)\n",
    "is_fraud = final_upsampled[final_upsampled.Class==1]\n",
    "fraud_not = final_upsampled[final_upsampled.Class==0]\n",
    "len(is_fraud),len(fraud_not),len(final_upsampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our upsampled data has an equal class values\n",
    "\n",
    "\n",
    "## modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have now prepared our data fro modelling, we will use the following  and compare their results\n",
    "\n",
    "    1. Logistic Regression\n",
    "    2. RandomForestClassifier\n",
    "    3. KNeighbors classifier\n",
    "    \n",
    " we are using the above algorithms because we are solving a classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "models= {\"KNN\":KNeighborsClassifier(),\n",
    "        \"LogisticRegression\":LogisticRegression(),\n",
    "        \"RandomForestClassifier\":RandomForestClassifier()}\n",
    "\n",
    "# create a function to fit and score the models above\n",
    "def fit_score_models(models,x_train,X_test,y_train,y_test):\n",
    "    \"\"\"\n",
    "    it helps in fitting and scoring the mentioned models\n",
    "    \"\"\"\n",
    "    np.random_state = 21\n",
    "    model_scores = {}\n",
    "    for name,model in models.items():\n",
    "        model.fit(x_train,y_train)\n",
    "        model_scores[name] = model.score(X_test,y_test)\n",
    "    return model_scores\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KNN': 0.6543535620052771,\n",
       " 'LogisticRegression': 0.9349164467897977,\n",
       " 'RandomForestClassifier': 0.9595426561125769}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores = fit_score_models(models=models,x_train=x_train,X_test=x_test,y_train=y_train,y_test=y_test)\n",
    "model_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x14f0816ee50>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_compare = pd.DataFrame(model_scores,index=['accuracy'])\n",
    "\n",
    "model_compare.T.plot.bar()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**we will use RandomizedSearchCv to fine tune our parameters to come up with the best, RandomizedSearchCV automatically tries different combinations,evaluates them, and saves the best**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different hyperparameters for logisticregression\n",
    "log_reg_grid = {\"C\":np.logspace(-4,4,20),\n",
    "               \"solver\":[\"liblinear\"]}\n",
    "\n",
    "# different hyperparameters for randomforestclassifier\n",
    "rf_grid = {\"n_estimators\":np.arange(10,1000,50),\n",
    "          \"max_depth\":[None,3,5,10],\n",
    "          \"min_samples_split\":np.arange(2,20,2),\n",
    "          \"min_samples_leaf\":np.arange(1,20,2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                dual=False, fit_intercept=True,\n",
       "                                                intercept_scaling=1,\n",
       "                                                l1_ratio=None, max_iter=100,\n",
       "                                                multi_class='auto', n_jobs=None,\n",
       "                                                penalty='l2', random_state=None,\n",
       "                                                solver='lbfgs', tol=0.0001,\n",
       "                                                verbose=0, warm_start=False),\n",
       "                   iid='deprecated', n_iter=20, n_jobs=None,\n",
       "                   param_distributions={'C':...\n",
       "       4.83293024e-03, 1.27427499e-02, 3.35981829e-02, 8.85866790e-02,\n",
       "       2.33572147e-01, 6.15848211e-01, 1.62377674e+00, 4.28133240e+00,\n",
       "       1.12883789e+01, 2.97635144e+01, 7.84759970e+01, 2.06913808e+02,\n",
       "       5.45559478e+02, 1.43844989e+03, 3.79269019e+03, 1.00000000e+04]),\n",
       "                                        'solver': ['liblinear']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using RandimzedsearchCV\n",
    "\n",
    "rs_log_reg = RandomizedSearchCV(LogisticRegression(),\n",
    "                               param_distributions=log_reg_grid,\n",
    "                               n_iter=20,\n",
    "                               cv=5,\n",
    "                               verbose=True)\n",
    "rs_log_reg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'solver': 'liblinear', 'C': 3792.690190732246}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_log_reg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9454705364995603"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_log_reg.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we have tuned LogisticRegression and have improved on our model, from 0.93 to 0.945,\n",
    "\n",
    "**let's improve our RandomForestClasssifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  4.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    ccp_alpha=0.0,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    max_samples=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators=100,\n",
       "                                                    n_jobs...\n",
       "                   param_distributions={'max_depth': [None, 3, 5, 10],\n",
       "                                        'min_samples_leaf': array([ 1,  3,  5,  7,  9, 11, 13, 15, 17, 19]),\n",
       "                                        'min_samples_split': array([ 2,  4,  6,  8, 10, 12, 14, 16, 18]),\n",
       "                                        'n_estimators': array([ 10,  60, 110, 160, 210, 260, 310, 360, 410, 460, 510, 560, 610,\n",
       "       660, 710, 760, 810, 860, 910, 960])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## improving randomforestclassifier\n",
    "\n",
    "\n",
    "rs_rf = RandomizedSearchCV(RandomForestClassifier(),\n",
    "                          param_distributions = rf_grid,\n",
    "                          cv = 5,\n",
    "                          n_iter = 20,\n",
    "                          verbose = True)\n",
    "rs_rf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 860,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_depth': None}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9525065963060686"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluating the model\n",
    "rs_rf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning the models hyperparamters has helped us improve the score,Randomizedsearchcv takes a lot of time if your computer power is average, i tried running it on google colab's gpu, it also took hours, if you compare the two models, randomforestClassifiier has a higher accuracy value than LogisticRegression, we will further improve our randomForestclassifier with gridSearchCV\n",
    "\n",
    "**The difference between RandomizedSearchCV and GridSearchCV is where RandomizedSearchCV searches over a grid of hyperparameters performing n_iter combinations, GridSearchCV will test every single possible combination.**\n",
    "\n",
    "In short:\n",
    "\n",
    "**RandomizedSearchCV - tries n_iter combinations of hyperparameters and saves the best.**\n",
    "\n",
    "**GridSearchCV - tries every single combination of hyperparameters and saves the best.**\n",
    "\n",
    "**Let's see it in action.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    7.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'min_samples_leaf': [1], 'min_samples_split': [2],\n",
       "                         'n_estimators': [210]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid_search ={\"n_estimators\":[210],\n",
    "          \"min_samples_split\":[2],\n",
    "          \"min_samples_leaf\":[1]}\n",
    "rf_gs = GridSearchCV(RandomForestClassifier(),\n",
    "                    param_grid=rf_grid_search,\n",
    "                    cv=5,\n",
    "                    verbose=True)\n",
    "rf_gs.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 210}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9507475813544415"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_gs.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from accuracy, we can get other metrics from our tuned model such as:\n",
    "\n",
    "    * ROC and AUC (plot_roc curve)\n",
    "    * F1 Score\n",
    "    * Precision score\n",
    "    * Recall score\n",
    "    * Confusion matrix\n",
    "    \n",
    "  to access all of the above metrics, we need to make predictions using our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "clf = RandomForestClassifier(n_estimators=210,min_samples_leaf=1,min_samples_split=2)\n",
    "clf.fit(x_train,y_train)\n",
    "y_preds = clf.predict(x_test)\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start our metrics with ROC\n",
    "\n",
    "* what is ROC?\n",
    "    \n",
    "    it is a plot that compares the true positive rate to the false positive rate, true positive occurs when the model predicts 1 and the correct value is 1. false negative occurs when model predicts 0 but the true value is 1\n",
    "    \n",
    "\n",
    "Scikit learn has an inbuilt functionality called plot_roc_curve() that will help us with the plottting.\n",
    "from the documentation, you can see that it takes n_estimator which in this case is our gridsearch tuned model, and the data to test on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x14f081c0d90>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# aperfect model will have an AUC of 1\n",
    "plot_roc_curve(clf,x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our model has an AUC = 0.98 which is close to perfection, a perfect model achieves an AUC of 1, our model still has room for improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Confusion matrix - it is a visual way to display where your model made the right predictions and the wrong predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[566   5]\n",
      " [ 43 523]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our model predicted 1, 5 times when it was suppossed to predict 0, it also predicted 0, 50 times when the correct value was 1.\n",
    "you can use heatmap to get a better visual representation of confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       571\n",
      "           1       0.99      0.92      0.96       566\n",
      "\n",
      "    accuracy                           0.96      1137\n",
      "   macro avg       0.96      0.96      0.96      1137\n",
      "weighted avg       0.96      0.96      0.96      1137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show classification report\n",
    "\n",
    "print(classification_report(y_test,y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's going on here?\n",
    "\n",
    "Let's get a refresh.\n",
    "\n",
    "* **Precision** - Indicates the proportion of positive identifications (model predicted class 1) which were actually correct. A model which produces no false positives has a precision of 1.0.\n",
    "* **Recall** - Indicates the proportion of actual positives which were correctly classified. A model which produces no false negatives has a recall of 1.0.\n",
    "* **F1 score** - A combination of precision and recall. A perfect model achieves an F1 score of 1.0.\n",
    "* **Support** - The number of samples each metric was calculated on.\n",
    "* **Accuracy** - The accuracy of the model in decimal form. Perfect accuracy is equal to 1.0.\n",
    "* **Macro avg** - Short for macro average, the average precision, recall and F1 score between classes. Macro avg doesn’t class imbalance into effort, so if you do have class imbalances, pay attention to this metric.\n",
    "* **Weighted avg** - Short for weighted average, the weighted average precision, recall and F1 score between classes. Weighted means each metric is calculated with respect to how many samples there are in each class. This metric will favour the majority class (e.g. will give a high value when one class out performs another due to having more samples).\n",
    "\n",
    "Ok, now we've got a few deeper insights on our model. But these were all calculated using a single training and test set.\n",
    "\n",
    "What we'll do to make them more solid is calculate them using cross-validation.\n",
    "\n",
    "How?\n",
    "\n",
    "We'll take the best model along with the best hyperparameters and use [`cross_val_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) along with various `scoring` parameter values.\n",
    "\n",
    "`cross_val_score()` works by taking an estimator (machine learning model) along with data and labels. It then evaluates the machine learning model on the data and labels using cross-validation and a defined `scoring` parameter.\n",
    "\n",
    "Let's remind ourselves of the best hyperparameters and then see them in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8029633730540521"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_acc = np.mean(cross_val_score(clf,X,\n",
    "                         y,\n",
    "                        cv = 5,\n",
    "                        scoring = \"accuracy\"))\n",
    "cv_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7482801415459278"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_precision = np.mean(cross_val_score(clf,\n",
    "                              X,\n",
    "                              y,\n",
    "                              scoring=\"precision\"))\n",
    "cv_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7923314780457636"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_recall = np.mean(cross_val_score(clf,\n",
    "                           X,\n",
    "                           y,\n",
    "                           scoring = \"recall\"))\n",
    "cv_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6645905655260249"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_f1 = np.mean(cross_val_score(clf,\n",
    "                        X,\n",
    "                       y,\n",
    "                       scoring=\"f1\"))\n",
    "cv_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x14f0bd0cb20>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEsCAYAAADTvkjJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAbtElEQVR4nO3de7gcdZ3n8feHQMAL4CVHR5NAIgQ0Ks+gmYij44WLE9RNGMdLorsjiDLumAEGxjXsMAxGx1FcLzsaFRSEQTFGXJ2o8QmO9wtoDsiCSYgTA5hjQA73uxD47B9Vh206fU7XCX1S6crn9Tz9pH9Vv1P97UryOdW/rqqfbBMREf1vt7oLiIiI3kigR0Q0RAI9IqIhEugREQ2RQI+IaIgEekREQyTQozEkWdKB5fPPSPrHKn13QF0/kPT2HfFaVXTbN9G/Eui7OElvljQo6W5JN0j6tqSX1l3XY2X7nbbf91i3I2lGGf6796KuiSTpWEk/6davV/smdj4J9F2YpFOAjwMfAJ4O7Ad8ClgwSv+dPtRibJIm1V1DTJwE+i5K0r7AUuBdtv+P7XtsP2j7G7bfXfY5U9LFkr4g6U7gWEl7Svq4pC3l4+OS9iz7T5H0TUm3S7pV0o8l7Vaue4+k30m6S9IGSUd0qOkwSTe2ho6kv5B0Vfl8rqRLy+3fIOmTkiaP8v7Ol/T+lva7y5/ZIultbX1fI+mXku6UtFnSmS2rf1T+eXv5KebF5c+8TdJ6SbdJWi1p/5btHSXpGkl3SPokoDH+Hs6U9JVyH98l6WpJB0k6TdJNZT2vav17k3Ru+V5+J+n9kiZJeg7wGeDFZZ23t+yHT0taJeke4JUd9s0CSVeW7/83kuaVy4+VtKms61pJbxntfcROwnYeu+ADmAdsBXYfo8+ZwIPAMRS//B9H8UvgMuBpwADwM+B9Zf9/oQiVPcrHn1GE2cHAZuCZZb8ZwAGjvOZvgKNa2l8BlpTPXwgcBuxebmM9cHJLXwMHls/PB97f8l5/DzwPeAJwUVvfVwDPL9/jIWXfY1pqdet+KvfHRuA5ZS2nAz8r100B7gReX+6Dvyv389vH2Mf3A39ebuvfgGuBfyh//h3AtS39vw6cXb6PpwG/AP66XHcs8JO27Z8P3AG8pHx/e7Xtm7nl+qPK9VOBZ5fbvxM4uOz3DOC5df+7zWPsR47Qd11PBW62vbVLv0ttf932w7bvA94CLLV9k+1h4L3Afyv7PkjxH39/F0f7P3aRBg8BewKzJe1h+zrbvxnl9b4ELAKQtDfw6nIZti+3fZntrbavowi2l1d4r28EPm/7V7bvoQjRR9j+ge2ry/d4Vfl6Y233r4F/sb2+3H8fAP64PEp/NbDO9sW2H6QY0rqxS30/tr263NZXKH5RfrD8+eXADElPkvR04GiKX2L32L4J+BiwsMv2/932T8v3d3/buuOB82x/p1z/O9vXlOseBp4n6XG2b7C9tsvrRM0S6LuuW4ApFcbFN7e1nwlc39K+vlwG8GGKI9dLyo/qSwBsbwROpgjSmyQtl/RMOrsIeF05jPM64Arb1wOUQxHfLIdl7qQI0ikV3usz295Ha/1IepGk70salnQH8M4u290f+N/l0M/twK0Un0Smtr9W+QutfR+2+33L8/softE+1NIGeGL5unsAN7S89tkUR+pjGev1p1N8KnqU8hffmyj2xQ2SviXp2V1eJ2qWQN91XUrxUf+YLv3ab8e5hSJYRuxXLsP2XbZPtf0s4L8Ap4yMldu+yPZLy5818KGOL2avowjco4E3UwT8iE8D1wCzbO8D/E/GGJ9ucQNFcLXW3OoiYCUw3fa+FMNGI9vtdDvSzRTDHE9qeTzO9s/aX0uS2l77sdgM/AGY0vK6+9h+7hi1jrV8ZJsHdPyh4lPDURSfuq4BPruddccOkkDfRdm+AzgDWCbpGEmPl7SHpKMlnTXGj34JOF3SgKQp5Ta+ACDptZIOLEPsToqhlockHSzp8PKo+36Ko86HRtk+FAF7IvAyiiGIEXuX2727PFr87xXf7gqKL3RnS3o88E9t6/cGbrV9v6S5FL9IRgxTDD08q2XZZ4DTJD23fN/7SnpDue5bwHMlva789HMi8EcV6xyT7RuAS4CPSNpH0m6SDpA0Mjz0e2DaaF8Uj+Jc4DhJR5Tbmyrp2ZKeLmm+pCdQ/BK5m7H/zmInkEDfhdn+KHAKxZd6wxRHa4spvngbzfuBQeAq4GrginIZwCzgPyj+818KfMr2DyjGzz8I3Ewxnvw0iqPr0XyJ4ovK79m+uWX531OE7V0UR4tfrvg+v00xlv09iiGh77V1+RtgqaS7KH5BrWj52XuBfwZ+Wg5zHGb7axSfMJaXQz+/ovhEQVnvG8r3e0u5T35apc6K/gqYDKwDbgMupjiCpnxfa4EbJd3c+ccfzfYvgOMoxuLvAH5I8SlqN+BUik9ft1J8p/A3PXsXMSFUDPFFRES/yxF6RERDJNAjIhoigR4R0RAJ9IiIhqjtZktTpkzxjBkz6nr5iIi+dPnll99se6DTutoCfcaMGQwODtb18hERfUnS9aOty5BLRERDJNAjIhoigR4R0RAJ9IiIhkigR0Q0RAI9IqIhKgW6pHkq5oHcODJpQdv6/coJAn4p6SpJr+59qRERMZauga5iwt5lFLcHnQ0skjS7rdvpwArbh1JMh/WpXhcaERFjq3KEPhfYaHuT7Qco5jhc0NbHwD7l830pZ7CJiIgdp8qVolN59JyEQ8CL2vqcSTGP5N9SzBZ+ZE+qG6cZS75Vx8uO23UffE3dJUREA1U5Qu80Z2P7rBiLgPNtT6OY9fxCSdtsW9IJkgYlDQ4PD4+/2oiIGFWVQB/i0ZPcTmPbIZXjKaftsn0psBcdZk23fY7tObbnDAx0vLdMRERspypDLmuAWZJmAr+j+NLzzW19fgscAZwv6TkUgZ5D8IhShgNjR+h6hG57K8XEwauB9RRns6yVtFTS/LLbqcA7JP1figl+j3UmK42I2KEq3T7X9ipgVduyM1qerwNe0tvSIiJiPHKlaEREQyTQIyIaIoEeEdEQCfSIiIZIoEdENEQCPSKiIRLoERENkUCPiGiIShcWxa4pl6tH9JccoUdENEQCPSKiIRLoERENkUCPiGiIBHpEREMk0CMiGiKBHhHREAn0iIiGqBTokuZJ2iBpo6QlHdZ/TNKV5ePXkm7vfakRETGWrleKSpoELAOOAoaANZJWltPOAWD771r6/y1w6ATUGhERY6hyhD4X2Gh7k+0HgOXAgjH6L6KYKDoiInagKoE+Fdjc0h4ql21D0v7ATOB7o6w/QdKgpMHh4eHx1hoREWOoEujqsMyj9F0IXGz7oU4rbZ9je47tOQMDA1VrjIiICqoE+hAwvaU9DdgySt+FZLglIqIWVQJ9DTBL0kxJkylCe2V7J0kHA08GLu1tiRERUUXXQLe9FVgMrAbWAytsr5W0VNL8lq6LgOW2RxuOiYiICVRpggvbq4BVbcvOaGuf2buyIiJivHKlaEREQyTQIyIaIoEeEdEQCfSIiIao9KVoRMTOZMaSb9VdQiXXffA1O/T1coQeEdEQCfSIiIZIoEdENEQCPSKiIRLoERENkUCPiGiIBHpEREMk0CMiGiKBHhHREAn0iIiGSKBHRDREAj0ioiEqBbqkeZI2SNooackofd4oaZ2ktZIu6m2ZERHRTde7LUqaBCwDjgKGgDWSVtpe19JnFnAa8BLbt0l62kQVHBERnVU5Qp8LbLS9yfYDwHJgQVufdwDLbN8GYPum3pYZERHdVAn0qcDmlvZQuazVQcBBkn4q6TJJ8zptSNIJkgYlDQ4PD29fxRER0VGVQFeHZW5r7w7MAl4BLAI+J+lJ2/yQfY7tObbnDAwMjLfWiIgYQ5VAHwKmt7SnAVs69Pl32w/avhbYQBHwERGxg1QJ9DXALEkzJU0GFgIr2/p8HXglgKQpFEMwm3pZaEREjK1roNveCiwGVgPrgRW210paKml+2W01cIukdcD3gXfbvmWiio6IiG1VmiTa9ipgVduyM1qeGzilfERERA1ypWhEREMk0CMiGiKBHhHREAn0iIiGSKBHRDREAj0ioiES6BERDZFAj4hoiAR6RERDJNAjIhoigR4R0RAJ9IiIhkigR0Q0RAI9IqIhEugREQ2RQI+IaIgEekREQ1QKdEnzJG2QtFHSkg7rj5U0LOnK8vH23pcaERFj6ToFnaRJwDLgKGAIWCNppe11bV2/bHvxBNQYEREVVDlCnwtstL3J9gPAcmDBxJYVERHjVSXQpwKbW9pD5bJ2fynpKkkXS5reaUOSTpA0KGlweHh4O8qNiIjRVAl0dVjmtvY3gBm2DwH+A7ig04Zsn2N7ju05AwMD46s0IiLGVCXQh4DWI+5pwJbWDrZvsf2HsvlZ4IW9KS8iIqqqEuhrgFmSZkqaDCwEVrZ2kPSMluZ8YH3vSoyIiCq6nuVie6ukxcBqYBJwnu21kpYCg7ZXAidKmg9sBW4Fjp3AmiMiooOugQ5gexWwqm3ZGS3PTwNO621pERExHrlSNCKiIRLoERENkUCPiGiIBHpEREMk0CMiGiKBHhHREAn0iIiGSKBHRDREAj0ioiES6BERDZFAj4hoiAR6RERDJNAjIhoigR4R0RAJ9IiIhkigR0Q0RKVAlzRP0gZJGyUtGaPf6yVZ0pzelRgREVV0DXRJk4BlwNHAbGCRpNkd+u0NnAj8vNdFRkREd1WO0OcCG21vsv0AsBxY0KHf+4CzgPt7WF9ERFRUJdCnAptb2kPlskdIOhSYbvubPawtIiLGoUqgq8MyP7JS2g34GHBq1w1JJ0galDQ4PDxcvcqIiOiqSqAPAdNb2tOALS3tvYHnAT+QdB1wGLCy0xejts+xPcf2nIGBge2vOiIitlEl0NcAsyTNlDQZWAisHFlp+w7bU2zPsD0DuAyYb3twQiqOiIiOuga67a3AYmA1sB5YYXutpKWS5k90gRERUc3uVTrZXgWsalt2xih9X/HYy4qIiPHKlaIREQ2RQI+IaIgEekREQyTQIyIaIoEeEdEQCfSIiIZIoEdENEQCPSKiIRLoERENkUCPiGiIBHpEREMk0CMiGiKBHhHREAn0iIiGSKBHRDREAj0ioiES6BERDVEp0CXNk7RB0kZJSzqsf6ekqyVdKeknkmb3vtSIiBhL10CXNAlYBhwNzAYWdQjsi2w/3/YfA2cBH+15pRERMaYqR+hzgY22N9l+AFgOLGjtYPvOluYTAPeuxIiIqKLKJNFTgc0t7SHgRe2dJL0LOAWYDBzek+oiIqKyKkfo6rBsmyNw28tsHwC8Bzi944akEyQNShocHh4eX6URETGmKoE+BExvaU8DtozRfzlwTKcVts+xPcf2nIGBgepVRkREV1UCfQ0wS9JMSZOBhcDK1g6SZrU0XwP8Z+9KjIiIKrqOodveKmkxsBqYBJxne62kpcCg7ZXAYklHAg8CtwFvnciiIyJiW1W+FMX2KmBV27IzWp6f1OO6IiJinHKlaEREQyTQIyIaIoEeEdEQCfSIiIZIoEdENEQCPSKiIRLoERENkUCPiGiIBHpEREMk0CMiGiKBHhHREAn0iIiGSKBHRDREAj0ioiES6BERDZFAj4hoiAR6RERDVAp0SfMkbZC0UdKSDutPkbRO0lWSvitp/96XGhERY+ka6JImAcuAo4HZwCJJs9u6/RKYY/sQ4GLgrF4XGhERY6tyhD4X2Gh7k+0HgOXAgtYOtr9v+96yeRkwrbdlRkREN1UCfSqwuaU9VC4bzfHAtzutkHSCpEFJg8PDw9WrjIiIrqoEujosc8eO0n8F5gAf7rTe9jm259ieMzAwUL3KiIjoavcKfYaA6S3tacCW9k6SjgT+AXi57T/0pryIiKiqyhH6GmCWpJmSJgMLgZWtHSQdCpwNzLd9U+/LjIiIbroGuu2twGJgNbAeWGF7raSlkuaX3T4MPBH4iqQrJa0cZXMRETFBqgy5YHsVsKpt2Rktz4/scV0RETFOuVI0IqIhEugREQ2RQI+IaIgEekREQyTQIyIaIoEeEdEQCfSIiIZIoEdENEQCPSKiIRLoERENkUCPiGiIBHpEREMk0CMiGiKBHhHREAn0iIiGSKBHRDREAj0ioiEqBbqkeZI2SNooaUmH9S+TdIWkrZJe3/syIyKim66BLmkSsAw4GpgNLJI0u63bb4FjgYt6XWBERFRTZU7RucBG25sAJC0HFgDrRjrYvq5c9/AE1BgRERVUGXKZCmxuaQ+Vy8ZN0gmSBiUNDg8Pb88mIiJiFFUCXR2WeXtezPY5tufYnjMwMLA9m4iIiFFUCfQhYHpLexqwZWLKiYiI7VUl0NcAsyTNlDQZWAisnNiyIiJivLoGuu2twGJgNbAeWGF7raSlkuYDSPoTSUPAG4CzJa2dyKIjImJbVc5ywfYqYFXbsjNanq+hGIqJiIia5ErRiIiGSKBHRDREAj0ioiES6BERDZFAj4hoiAR6RERDJNAjIhoigR4R0RAJ9IiIhkigR0Q0RAI9IqIhEugREQ2RQI+IaIgEekREQyTQIyIaIoEeEdEQCfSIiIaoFOiS5knaIGmjpCUd1u8p6cvl+p9LmtHrQiMiYmxdA13SJGAZcDQwG1gkaXZbt+OB22wfCHwM+FCvC42IiLFVOUKfC2y0vcn2A8ByYEFbnwXABeXzi4EjJKl3ZUZERDdVJomeCmxuaQ8BLxqtj+2tku4Angrc3NpJ0gnACWXzbkkbtqfoHWwKbe/jsdKu/fkl+7N3si97q1/25/6jragS6J2OtL0dfbB9DnBOhdfcaUgatD2n7jqaIvuzd7Ive6sJ+7PKkMsQML2lPQ3YMlofSbsD+wK39qLAiIiopkqgrwFmSZopaTKwEFjZ1mcl8Nby+euB79ne5gg9IiImTtchl3JMfDGwGpgEnGd7raSlwKDtlcC5wIWSNlIcmS+cyKJ3sL4aIuoD2Z+9k33ZW32/P5UD6YiIZsiVohERDZFAj4hoiAR6RERDJNAjIhqiyoVFu5TyjJ4v2r6t7lqaRNJUiivcHvk3Z/tH9VXUXySdMtZ62x/dUbU0naRn276m7jq2RwJ9W38ErJF0BXAesDrn1D82kj4EvAlYBzxULjaQQK9u77oL2IVcAuxXdxHbI6ctdlDeWOxVwHHAHGAFcK7t39RaWJ8q79lziO0/1F1LBICkfx1tFfBW2/vsyHp6JUfoHdi2pBuBG4GtwJOBiyV9x/b/qLe6vrQJ2ANIoG+nMQIIANsn7qhaGuI44FQ6/5tctINr6ZkEehtJJ1LcxuBm4HPAu20/KGk34D+BBPr43QtcKem7tPwHSgiNy+V1F9Awa4Bf2f5Z+wpJZ+74cnojQy5tylsanGv7+g7rnmN7fQ1l9TVJb+203PYFnZZHTDRJTwHut31v3bX0UgK9jaTDgLW27yrbewOzbf+83sr6W3ljt4PK5gbbD9ZZT7+SNAC8h2L2sL1Glts+vLai+pCk/Wz/tu46ei3noW/r08DdLe17ymWxnSS9gmK4ahnwKeDXkl5Wa1H964vAemAm8F7gOorhgxifr488kfTVOgvppYyhb0utpynafri8x3tsv48Ar7K9AUDSQcCXgBfWWlV/eqrtcyWdZPuHwA8l/bDuovpQ66Q8z6qtih7LEfq2Nkk6UdIe5eMkirM0YvvtMRLmALZ/TXHWS4zfyFDVDZJeI+lQiklnYnw8yvO+ljH0NpKeBvwrcDjFX/R3gZNt31RrYX1M0nkU+/LCctFbgN1tH1dfVf1J0muBH1PMEPYJYB/gveW8BFGRpIcohlMFPI7iTCzKtvv1PPQEekw4SXsC7wJeSvEf5kfAp3KhUURvJdDbSNoLOB54Lo8+i+BttRUVUZJ0AXCS7dvL9pOBj+TfZ0DG0Du5kOJ+Ln8O/JBifPKuWivqU5JWlH9eLemq9kfd9fWpQ0bCHKC8idyhNdYTO5GcvbGtA22/QdIC2xdIuohiPtUYv5PKP19baxXNspukJ4/cDbS8QCb/jwPIP4RORs4iuF3S8yju5zKjvnL6l+0byqc3A/eVp4AeBDwb+HZ9lfW1jwA/k3QxxRfNbwT+ud6SYmeRMfQ2kt4OfBV4PnA+8ETgH22fXWdd/UzS5cCfUdzk7DJgELjX9ltqLaxPSZpNcRaWgO/aXldzSbGTyBF6i/IGXHeWH2d/RIMuOKiZbN8r6XjgE7bPkvTLuovqY08B7rH9eUkDkmbavrbuoqJ++VK0he2HgcV119FAkvRiivPPv1Uuy8HEdpD0TxT3cjmtXLQH8IX6KoqdSQJ9W9+R9PeSpkt6ysij7qL63MkUAfQ122slPQv4fs019au/AOZTXBSD7S1kNqMoZQy9jaROH11tO8MvUTtJv7A9V9IVtl8g6QnApbYPqbu2qF8+9raxPbPuGppC0sdtnyzpG3S4X4bt+TWU1e9WSDobeJKkdwBvo5iIJSJH6O0k/VWn5bb/bUfX0u8kvdD25ZJe3ml9ebfAGCdJR1HMeSuKScy/U3NJsZNIoLeR9ImW5l7AEcAVtl9fU0l9rxwWuK/80hlJk4A9mzZbTB3KfbnQ9hfrriXql0DvQtK+wIUZHth+ki4DjrR9d9l+InCJ7T+tt7L+IWkfihucTQVWAt8p2+8GrrS9oMbyYieRMfTu7gVm1V1En9trJMwBbN8t6fF1FtSHLgRuAy4F3k4R5JOBBbavrLOw2Hkk0Nu0fYG3G8XcjSvqq6gR7pH0AttXQDG2DtxXc0395lm2nw8g6XMUt1PYb2Tu2whIoHfyv1qebwWutz1UVzENcTLwFUlbyvYzgDfVWE8/emRSbdsPSbo2YR7tMobeRtJM4Abb95ftxwFPt31drYX1OUl7AAdTnJlxje0Hu/xItGiZYQcePctOX8+wE72VQG8jaRD4U9sPlO3JwE9t/0m9lfWvcrz8FGB/2++QNAs42PY3ay4tolFy6f+2dh8Jc4Dy+eQa62mCzwMPAC8u20PA++srJ6KZEujbGpb0yCmKkhZQfAEV2+8A22dRjgPbvo9iqCAieihfim7rncAXJX2ybA8BHa8ejcoeKL+LMICkA4BMEB3RYxlDH0V58YtyJsFjV16qfjrFKaCXAC8BjrX9gzrrimiaBHobSR8AzmqbVf1U26fXW1l/kiSKibbvBQ6jGGq5zHaGsSJ6LIHeRtIvbR/atuwK2y+oq6Z+J+ly2y+su46IpsuXotuaJGnPkUY59rvnGP2ju8sk5bTPiAmWL0W39QXgu5I+X7aPAy6osZ4meCXwTknXUVwcM3IxTCZliOihDLl0IGkecCRF8NwGPMP2u+qtqn9J2r/TctvX7+haIposR+id3Qg8DLwRuBb4ar3l9CdJe1GcBnogcDVwru2t9VYV0VwJ9JKkg4CFwCLgFuDLFJ9gXllrYf3tAoqLiX4MHE1x2uJJtVYU0WAZcilJepgieI63vbFctimTQ28/SVe33PJ1d+AXOVsoYuLkLJf/7y8phlq+L+mzko4gl6c/Vq23fM1QS8QEyxF6m3L+y2Mohl4Opxg2+JrtS2otrA/llq8RO1YCfQySngK8AXiT7cPrriciYiwJ9IiIhsgYekREQyTQIyIaIoEeEdEQCfSIiIb4f5wvjzWG8rnjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv_metrics = pd.DataFrame({\"Accuracy\":cv_acc,\n",
    "                          \"Precision\":cv_precision,\n",
    "                          \"Recall\":cv_recall,\n",
    "                          \"F1\":cv_f1},\n",
    "                         index=[0])\n",
    "\n",
    "cv_metrics.T.plot.bar(title=\"Cross validated metrics\",legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "\n",
    "the last we are going to look at is feature importance, this is finding the features that most contributed to the outcome of our model,in our case, the features that helped the model predict whether a transaction is fraud or not.\n",
    "\n",
    "Since we are using RandomForestClassifier, we need to find out how to get the feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00463277, 0.00833555, 0.02365482, 0.03973469, 0.11878815,\n",
       "       0.00724087, 0.01622086, 0.03308373, 0.00896498, 0.02500244,\n",
       "       0.10483163, 0.07643594, 0.08538749, 0.00829516, 0.16384959,\n",
       "       0.00644101, 0.03611068, 0.10897196, 0.01115594, 0.01534551,\n",
       "       0.01362544, 0.01674283, 0.00722187, 0.0071035 , 0.00431549,\n",
       "       0.00667426, 0.00706056, 0.01516094, 0.0076244 , 0.01198696])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's fit an instance of RandomForest using clf\n",
    "clf.fit(x_train,y_train)\n",
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looking at it like these migght not make much sense, so we will combine with columns from our dataframe and zip it together so that it makes sense to us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Time': 0.004632770832747444,\n",
       " 'V1': 0.008335550932104165,\n",
       " 'V2': 0.023654817315212684,\n",
       " 'V3': 0.03973469415574418,\n",
       " 'V4': 0.11878815484510917,\n",
       " 'V5': 0.007240865290846399,\n",
       " 'V6': 0.01622085937192827,\n",
       " 'V7': 0.03308372933118681,\n",
       " 'V8': 0.008964978353420151,\n",
       " 'V9': 0.02500243516512122,\n",
       " 'V10': 0.10483162854230701,\n",
       " 'V11': 0.07643594001237633,\n",
       " 'V12': 0.08538748635435786,\n",
       " 'V13': 0.00829515754112598,\n",
       " 'V14': 0.16384959205223876,\n",
       " 'V15': 0.006441009732540201,\n",
       " 'V16': 0.03611068039852141,\n",
       " 'V17': 0.10897195917342066,\n",
       " 'V18': 0.01115593722654526,\n",
       " 'V19': 0.015345506108751338,\n",
       " 'V20': 0.013625436717736559,\n",
       " 'V21': 0.016742833647984418,\n",
       " 'V22': 0.007221870667987003,\n",
       " 'V23': 0.00710349876814251,\n",
       " 'V24': 0.004315494646772879,\n",
       " 'V25': 0.006674260309611323,\n",
       " 'V26': 0.0070605570194298035,\n",
       " 'V27': 0.015160937077831256,\n",
       " 'V28': 0.007624395505566083,\n",
       " 'Amount': 0.011986962903332798}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance = dict(zip(df.columns,list(clf.feature_importances_)))\n",
    "feature_importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x14f0bd0cd60>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_df = pd.DataFrame(feature_importance,index=[0])\n",
    "feature_df.T.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result from above bar graph suggest that only 4 out of the 30 features as being important to our prediction model, feature importance helps in filtering out columns that would otherwise take space and consume computing power, while they do not contribute alot to our prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
